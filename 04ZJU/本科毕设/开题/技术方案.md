利用因果网络完成场景构建，场景可以从静态场景和动态场景分别入手。

### 第一部分：静态场景生成（不存在交互）
高维度优化搜索问题，默认十字路口所有的行人和车辆只存在两个参数，出发时间 t 和速度 v，可以设置静态障碍物（位置）
### 基于博弈的场景生成
利用因果网络完成场景的构建，课程强化学习用于在因果网络中添加扰动，因果网络中的交互策略使用博弈模型完成建模，将待测车辆设置为主车，采用 Stackelberg 模型，考虑不完全信息情况下的博弈。

#### **1. 优化目标**
通过以下多目标联合优化实现动态场景生成：
$$
\min_{G, \pi_{\text{leader}}} \max_{D, \pi_{\text{follower}}} \mathcal{L}_{\text{total}} = \mathcal{L}_{\text{Game}} + \mathcal{L}_{\text{Generation}} + \mathcal{L}_{\text{Curriculum}} + \mathcal{L}_{\text{Causal}}
$$

---

#### **2. 动态博弈与生成模型的融合（$\mathcal{L}_{\text{Game}}$ 和 $\mathcal{L}_{\text{Generation}}$）**
- **博弈驱动的关键点生成**  
  主车作为领导者生成策略 $\pi_{\text{leader}}$，周围车辆通过逆向强化学习推断其奖励函数 $R_{\text{follower}}$，并生成对抗性策略 $\pi_{\text{follower}}$。两者的博弈结果被编码为稀疏关键点序列 $\{p_k\}$，通过扩散模型生成：  
  $$
  \mathcal{L}_{\text{Game}} = \underbrace{\mathbb{E}\left[ R_{\text{leader}} - \lambda D_{\text{KL}}(P_{\text{follower}} \| P_{\text{real}}) \right]}_{\text{Stackelberg博弈收益}} + \underbrace{\mathbb{E}_{z \sim p(z)} \left[ \| G(z) - p_{\text{real}} \|^2 \right]}_{\text{生成损失}}
  $$

- **生成模型的条件化生成**  
  生成模型 $G(z)$ 以博弈策略 $\pi_{\text{leader}}$ 和 $\pi_{\text{follower}}$ 为条件，生成符合博弈动态的关键点：
  $$
  p(t) = G(z | \pi_{\text{leader}}, \pi_{\text{follower}}), \quad z \sim \mathcal{N}(0, I)
  $$

---
#### **3. 动态难度调节（$\mathcal{L}_{\text{Curriculum}}$）**
  通过课程学习动态调整生成场景的交互密度 $D$ 和不确定性 $U$，生成器 $G$ 需满足：
  $$
  \mathcal{L}_{\text{Curriculum}} = \gamma \cdot \left( \frac{D - D_{\text{target}}}{D_{\text{max}} - D_{\text{min}}} \right)^2 + \eta \cdot \left( U - U_{\text{target}} \right)^2
  $$
  其中 $D_{\text{target}}$ 和 $U_{\text{target}}$ 根据当前模型能力动态调整，$\gamma, \eta$ 为权重系数。

---
#### **4. 因果干预与反事实生成（$\mathcal{L}_{\text{Causal}}$）**

- **因果驱动的场景多样性**  
  在结构因果模型（SCM）中对关键变量 $X_j$ 施加干预 $do(X_j = x')$，生成反事实关键点 $p_{\text{counterfactual}}$：
  $$
  \mathcal{L}_{\text{Causal}} = \mathbb{E}_{do(X_j)} \left[ \| G(z | do(X_j)) - p_{\text{counterfactual}} \|^2 \right]
  $$

---
